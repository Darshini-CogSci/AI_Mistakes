{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f294a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image, ImageDraw, ImageFont \n",
    "from torchvision import models, transforms\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pathlib import Path \n",
    "\n",
    "# --- Import Utilities for 16-Class Classification ---\n",
    "from helper.human_categories import HumanCategories, get_human_object_recognition_categories\n",
    "from helper.probabilities_to_decision import ImageNetProbabilitiesTo16ClassesMapping\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# ---------------- Preprocessing ----------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "def load_image(path):\n",
    "    \"\"\"Loads an image and converts it to a normalized PyTorch tensor.\"\"\"\n",
    "    img = Image.open(path).convert(\"RGB\")\n",
    "    tensor = transform(img).unsqueeze(0)\n",
    "    return img, tensor\n",
    "\n",
    "# ---------------- ROBUST MODEL LOADER ----------------\n",
    "from collections import OrderedDict\n",
    "\n",
    "def load_model(weights_path, device):\n",
    "    \"\"\"\n",
    "    Load a ResNet-50 model from various checkpoint formats:\n",
    "    - plain state_dict\n",
    "    - dict with 'state_dict' or 'model' keys\n",
    "    - keys possibly prefixed with 'module.' or 'model.'\n",
    "    \"\"\"\n",
    "    model = models.resnet50(weights=None).to(device)\n",
    "    \n",
    "    ckpt = torch.load(weights_path, map_location=\"cpu\")\n",
    "    \n",
    "    # Figure out where the actual state_dict lives\n",
    "    if isinstance(ckpt, dict):\n",
    "        if \"state_dict\" in ckpt and isinstance(ckpt[\"state_dict\"], dict):\n",
    "            state_dict = ckpt[\"state_dict\"]\n",
    "        elif \"model\" in ckpt and isinstance(ckpt[\"model\"], dict):\n",
    "            state_dict = ckpt[\"model\"]\n",
    "        else:\n",
    "            state_dict = ckpt\n",
    "    else:\n",
    "        state_dict = ckpt\n",
    "\n",
    "    # Clean keys: strip possible 'module.' / 'model.' prefixes\n",
    "    clean_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        new_k = k\n",
    "        if new_k.startswith(\"module.\"):\n",
    "            new_k = new_k[len(\"module.\"):]\n",
    "        if new_k.startswith(\"model.\"):\n",
    "            new_k = new_k[len(\"model.\"):]\n",
    "        clean_state_dict[new_k] = v\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(clean_state_dict, strict=False)\n",
    "    print(f\"Loaded weights from: {weights_path}\")\n",
    "    if missing:\n",
    "        print(\"Missing keys:\", missing)\n",
    "    if unexpected:\n",
    "        print(\"Unexpected keys:\", unexpected)\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# --- FUNCTION TO DRAW TEXT ---\n",
    "def draw_text_on_image(image_array, text):\n",
    "    \"\"\"Draws the predicted class text onto the image array.\"\"\"\n",
    "    image_array = np.uint8(np.clip(image_array, 0, 255))\n",
    "    pil_img = Image.fromarray(image_array)\n",
    "    draw = ImageDraw.Draw(pil_img)\n",
    "    \n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", size=18)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "        \n",
    "    draw.text(\n",
    "        (10, 10),\n",
    "        text,\n",
    "        fill=(0, 0, 0),\n",
    "        font=font,\n",
    "        stroke_fill=(255, 255, 255),\n",
    "        stroke_width=2\n",
    "    )\n",
    "    \n",
    "    return np.array(pil_img)\n",
    "# -----------------------------\n",
    "\n",
    "def get_winning_broad_category(model_outputs, decision_mapper):\n",
    "    \"\"\"Determines the single winning broad class name.\"\"\"\n",
    "    probabilities_tensor = F.softmax(model_outputs, dim=1)\n",
    "    probabilities_np = probabilities_tensor.detach().cpu().numpy()[0]\n",
    "    best_broad_class = decision_mapper.probabilities_to_decision(probabilities_np)\n",
    "    return best_broad_class\n",
    "\n",
    "def apply_cam_overlay(rgb_img_255, grayscale_cam):\n",
    "    \"\"\"\n",
    "    Applies the heatmap overlay using aggressive blending (alpha=0.75)\n",
    "    for vivid visualization.\n",
    "    \"\"\"\n",
    "    # 1. Convert grayscale CAM to 0-255 BGR Jet Colormap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam), cv2.COLORMAP_JET)\n",
    "    \n",
    "    # 2. Convert original image to BGR\n",
    "    bgr_img_255 = cv2.cvtColor(rgb_img_255, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # 3. Blending (Aggressive Alpha: 75% Heatmap, 25% Background)\n",
    "    alpha = 0.4 \n",
    "    superimposed_img_bgr = cv2.addWeighted(bgr_img_255, 1.0 - alpha, heatmap, alpha, 0)\n",
    "    \n",
    "    # 4. Convert blended image back to RGB\n",
    "    final_visualization = cv2.cvtColor(superimposed_img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return final_visualization\n",
    "\n",
    "def run_gradcam_on_dataset(root_input, root_output, resnet_weights, use_cuda=False):\n",
    "    device = torch.device(\"cuda\" if use_cuda and torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    hc = HumanCategories()\n",
    "    decision_mapper = ImageNetProbabilitiesTo16ClassesMapping(aggregation_function=np.mean)\n",
    "\n",
    "    model = load_model(resnet_weights, device)\n",
    "\n",
    "    target_layers = [model.layer4[-1]]\n",
    "    cam = GradCAM(model=model, target_layers=target_layers)\n",
    "    \n",
    "    Path(root_output).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # ---- Walk through folder structure ----\n",
    "    for root, dirs, files in os.walk(root_input):\n",
    "        rel_path = os.path.relpath(root, root_input)\n",
    "        out_subdir = os.path.join(root_output, rel_path)\n",
    "        os.makedirs(out_subdir, exist_ok=True)\n",
    "\n",
    "        for fname in files:\n",
    "            if not fname.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
    "                continue\n",
    "\n",
    "            fpath = os.path.join(root, fname)\n",
    "            base_fname = os.path.splitext(fname)[0]\n",
    "            \n",
    "            try:\n",
    "                orig_img, input_tensor = load_image(fpath)\n",
    "                rgb_img_base = np.array(orig_img.resize((224, 224))).astype(np.uint8)\n",
    "\n",
    "                if orig_img.size[0] < 16 or orig_img.size[1] < 16:\n",
    "                    print(f\"Skipping tiny image: {fpath}\")\n",
    "                    continue\n",
    "            except Exception as e:\n",
    "                print(f\"Skipping unreadable file {fpath}. Error: {e}\")\n",
    "                continue\n",
    "\n",
    "            input_tensor = input_tensor.to(device)\n",
    "            \n",
    "            # --- 1. Get prediction and ALL fine category indices ---\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_tensor)\n",
    "\n",
    "            broad_class_name = get_winning_broad_category(outputs, decision_mapper)\n",
    "            winning_indices = hc.get_imagenet_indices_for_category(broad_class_name)\n",
    "            \n",
    "            all_cams = []\n",
    "            \n",
    "            if not winning_indices:\n",
    "                print(f\"No fine categories found for {broad_class_name}. Skipping image.\")\n",
    "                continue\n",
    "\n",
    "            # --- 2. Generate CAM for ALL fine categories and collect them ---\n",
    "            for fine_idx in winning_indices:\n",
    "                targets = [ClassifierOutputTarget(fine_idx)]\n",
    "                individual_cam = cam(input_tensor=input_tensor, targets=targets)[0, :]\n",
    "                all_cams.append(individual_cam)\n",
    "\n",
    "            # --- 3. Composite (Average) the individual heatmaps ---\n",
    "            composite_cam = np.mean(np.stack(all_cams, axis=0), axis=0)\n",
    "\n",
    "            # --- 4. Overlay and Save ---\n",
    "            heatmap_resized = cv2.resize(composite_cam, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
    "            final_visualization = apply_cam_overlay(rgb_img_base, heatmap_resized)\n",
    "            \n",
    "            # Draw the text onto the visualization\n",
    "            text_to_draw = f\"Classified as: {broad_class_name}\"\n",
    "            visualization_with_text = draw_text_on_image(final_visualization, text_to_draw)\n",
    "\n",
    "            # ---- Save result ----\n",
    "            out_fname = f\"{base_fname}_composite_gradcam_{broad_class_name.replace(' ', '_')}.jpg\"\n",
    "            out_path = os.path.join(out_subdir, out_fname)\n",
    "            \n",
    "            Image.fromarray(visualization_with_text).save(out_path)\n",
    "            print(f\"Saved COMPOSITE Heatmap for {broad_class_name}: {out_path}\")\n",
    "            \n",
    "run_gradcam_on_dataset(\n",
    "    root_input=\"./path/to/your/stimuli/file/\",\n",
    "    root_output=\"./path/to/your/output/file/\",\n",
    "    resnet_weights=\"./path/to/the/downloaded/resnet50/weight/\",\n",
    "    use_cuda=True  # or False if you want CPU\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
